# Titanic Survival Prediction ğŸš¢

This repository contains a complete workflow for predicting passenger survival on the **Titanic dataset** using machine learning.  
The project is structured into three main parts: **Exploratory Data Analysis (EDA)**, **Data Preprocessing**, and **Model Building**.

---

## ğŸ“‚ Repository Structure

- `titanicEda.ipynb` â€“ Exploratory Data Analysis (EDA) of the Titanic dataset, including:
  - Data overview and summary statistics
  - Missing value analysis
  - Feature distributions and correlations
  - Insights for feature engineering

- `DataPreprocessing.ipynb` â€“ Data cleaning and preprocessing steps:
  - Handling missing values
  - Encoding categorical variables
  - Feature scaling/normalization
  - Splitting into train/test sets

- `model.ipynb` â€“ Machine Learning model training and evaluation:
  - Multiple algorithms (e.g., Logistic Regression, Random Forest, XGBoost)
  - Model comparison
  - Hyperparameter tuning
  - Performance metrics (accuracy, precision, recall, F1-score, ROC-AUC)

---

## ğŸ› ï¸ Technologies Used

- **Python 3.x**
- **Jupyter Notebook**
- **Pandas, NumPy** â€“ data manipulation
- **Matplotlib, Seaborn** â€“ data visualization
- **Scikit-learn** â€“ preprocessing & machine learning models
- **RandomForestClassifier** â€“ Random Forest model
- **Logistic Regression** â€“ Logistic regression model
- **XGBoost** â€“ Ensemble Method



---
ğŸ“Š Results

Logistic regression Cross Validation performance
Accuracy: 0.807 (Â±0.020)
Precision: 0.732 (Â±0.031)
Recall: 0.789 (Â±0.071)
F1: 0.757 (Â±0.034)
Roc_auc: 0.863 (Â±0.024)

Random Forest Classifier Cross Validation performance
Accuracy: 0.802 (Â±0.034)
Precision: 0.754 (Â±0.046)
Recall: 0.722 (Â±0.068)
F1: 0.736 (Â±0.051)
Roc_auc: 0.856 (Â±0.041)

XGBoost Cross Validation performance
Accuracy: 0.810 (Â±0.026)
Precision: 0.753 (Â±0.047)
Recall: 0.760 (Â±0.036)
F1: 0.755 (Â±0.028)
Roc_auc: 0.857 (Â±0.028)

Logistic Regression seems to slightly outperform Random Forest Classifie
However, Random Forest might be the better choice for precision (minimizing false positives)

---
After Tuning

Best Parameters: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}

Tuned Random Forest Cross Validation performance
Accuracy: 0.829 (Â±0.027)
Precision: 0.786 (Â±0.036)
Recall: 0.766 (Â±0.075)
F1: 0.773 (Â±0.044)
Roc_auc: 0.869 (Â±0.037)

Key insights:

<img width="633" height="453" alt="download" src="https://github.com/user-attachments/assets/253c9026-2d9d-4082-8a4d-45470d4a04ea" />


Feature engineering improved prediction performance.
---


ğŸ“Œ Future Improvements

Deploy as a Flask/Streamlit web app for interactive predictions

Add automated hyperparameter optimization (GridSearchCV/Optuna)

Experiment with deep learning models (TensorFlow/Keras)
 

