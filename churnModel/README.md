# ğŸ“Š Churn Model â€“ Binary Classification

This project implements a **binary classification pipeline** to predict **customer churn** using the customer churn dataset

The workflow includes **EDA â†’ Preprocessing â†’ Model Training â†’ Evaluation â†’ Comparison â†’ Next Steps**.

---

## ğŸ“ Project Structure

```
Classification/churnModel/
â”‚â”€â”€ new_models.ipynb        # Main notebook (EDA + modeling + evaluation)
â”‚â”€â”€ base_models/            # Trained models saved as .joblib
â”‚â”€â”€ X_train.joblib          # Preprocessed training features
â”‚â”€â”€ X_test.joblib           # Preprocessed test features
â”‚â”€â”€ y_train.joblib          # Training labels
â”‚â”€â”€ y_test.joblib           # Test labels
â”‚â”€â”€ README.md               # Documentation
```
.joblib files were large so did not push it on repo
---

## âš™ï¸ Workflow

### 1. Exploratory Data Analysis (EDA)

* **Data Info & Structure** â†’ shape, dtypes, null checks
* **Missing Values** â†’ handled with imputation/removal
* **Target Distribution** â†’ churn vs non-churn imbalance (countplot / pie chart)
* **Numerical Features** â†’ histograms, boxplots, KDE plots
* **Categorical Features** â†’ countplots, frequency tables
* **Outliers** â†’ IQR method + visualization
* **Correlation Analysis** â†’ heatmap, pairplot

### 2. Preprocessing

* Dropped irrelevant columns (`id`)
* Encoded categorical features
* Feature scaling where necessary
* Train-test split

### 3. Model Training

Baseline models trained and stored in `base_models/`:

* Logistic Regression
* Random Forest
* XGBoost
* LightGBM
* Support Vector Classifier (SVC)

### 4. Model Evaluation

For each model:

* Classification report (precision, recall, f1-score, accuracy)
* Confusion matrix
* ROC-AUC score
* ROC Curve & Precision-Recall Curve

### 5. Model Comparison

* Compared models on test set performance
* Identified best candidate (XGBoost / LightGBM) for further tuning

---

## ğŸ“ˆ Results (Summary)

| Model               | ROC-AUC | Notes                          |
| ------------------- | ------- | ------------------------------ |
| Logistic Regression | \~0.94  | Simple, interpretable          |
| Random Forest       | \~1.00  | Strong recall                  |
| XGBoost             | \~0.98  | Best balance overall           |
| KNN                 | \~0.97  | Fast & efficient               |
| SVM                 | \~0.94  | Needed probability calibration |


---

## ğŸ”® Next Steps

* Hyperparameter tuning (GridSearchCV / Optuna)
* Feature importance (tree-based & permutation importance)
* Threshold tuning (optimize recall/precision tradeoff)
* Model explainability (SHAP, LIME)
* Learning curves & error analysis
* Deployment (Flask / FastAPI / Streamlit app)

---
 
